{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55de5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import keras\n",
    "import pylab\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation,InputLayer\n",
    "from keras.layers import Embedding ,Reshape, Input, Lambda, Layer\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers,preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications\n",
    "from keras_self_attention import SeqSelfAttention ,SeqWeightedAttention\n",
    "from keras.layers import LSTM, Bidirectional,GRU,BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D,Conv2D ,Permute,MaxPooling2D,Flatten\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split,StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix,precision_score, f1_score, roc_auc_score,r2_score,matthews_corrcoef\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.models import load_model\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bad053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3d2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelToMat(labelIn):\n",
    "    \"\"\"\n",
    "    Change the label to matrix as the following:\n",
    "        [0,1,2,1,1] =>  [1,0,0]\n",
    "                        [0,1,0]\n",
    "                        [0,0,1]\n",
    "                        [0,1,0]\n",
    "                        [0,1,0]\n",
    "    Parameters:\n",
    "        labelIn: List, the list of the labels\n",
    "    \"\"\"\n",
    "    labelSet = set(labelIn)\n",
    "    arrLength = len(labelSet)\n",
    "    baseArr = [0] * arrLength\n",
    "    labelArrDict = {}\n",
    "    arrLabelDict = {}\n",
    "    for i, label in enumerate(np.sort(list(labelSet))):\n",
    "        tmpArr = baseArr.copy()\n",
    "        tmpArr[i] += 1\n",
    "        labelArrDict[label] = tmpArr\n",
    "        arrLabelDict[tuple(tmpArr)] = label\n",
    "    labelOut = []\n",
    "    for label in labelIn:\n",
    "        labelOut.append(labelArrDict[label])\n",
    "    return np.array(labelOut), labelArrDict, arrLabelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c932e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yList = np.load(\"yList.npy\",allow_pickle=True)#yList是八分类标签,yArr是八分类标签对应的1*8维标签\n",
    "tmpX1 = np.load('ADcX.npz')\n",
    "X1 = tmpX1[\"arr_0\"]\n",
    "tmpX2 = np.load('AtDrX.npz')\n",
    "X2 = tmpX2[\"arr_0\"]\n",
    "yArr,tmp,tmp1 = labelToMat(yList)\n",
    "X = np.concatenate([X1 , X2] , axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1e788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StratifiedShuffleSplit(n_splits=1,test_size=0.2,train_size=0.8,random_state=0)#分成5组，测试比例为0.2，训练比例是0.8\n",
    "for train_index, test_index in ss.split(X, yList):\n",
    "    X_train, X_test = X[train_index], X[test_index]#训练集对应的值\n",
    "    y_train, y_test = np.array(yList)[train_index], np.array(yList)[test_index]#类别集对应的值\n",
    "y_trainArr,tmp,tmp1 = labelToMat(y_train)\n",
    "y_testArr,tmp,tmp1 = labelToMat(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517873d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpList0 = copy.copy(y_train)\n",
    "tmpList1 = copy.copy(tmpList0)\n",
    "tmpList2 = copy.copy(tmpList1)\n",
    "tmpList3 = copy.copy(tmpList2)\n",
    "tmpList4 = copy.copy(tmpList3)\n",
    "tmpList5 = copy.copy(tmpList4)\n",
    "tmpList6 = copy.copy(tmpList5)\n",
    "tmpList7 = copy.copy(tmpList6)\n",
    "\n",
    "tmptestList0 = copy.copy(y_test)\n",
    "tmptestList1 = copy.copy(tmptestList0)\n",
    "tmptestList2 = copy.copy(tmptestList1)\n",
    "tmptestList3 = copy.copy(tmptestList2)\n",
    "tmptestList4 = copy.copy(tmptestList3)\n",
    "tmptestList5 = copy.copy(tmptestList4)\n",
    "tmptestList6 = copy.copy(tmptestList5)\n",
    "tmptestList7 = copy.copy(tmptestList6)\n",
    "#标签转换，将0-7 对应标签分别置为0 其余标签置为1(是谁谁变0，其余变1)\n",
    "yList0 = []\n",
    "for i in range(0,len(tmpList0)):\n",
    "    if tmpList0[i] != 0:\n",
    "        tmpList0[i] = 1\n",
    "    yList0.append(tmpList0[i])\n",
    "    i=i+1        \n",
    "    \n",
    "yList1 = []\n",
    "for i in range(0,len(tmpList1)):\n",
    "    if tmpList1[i] != 1:\n",
    "        tmpList1[i] = 1\n",
    "    elif  tmpList1[i] == 1:\n",
    "        tmpList1[i] = 0\n",
    "    yList1.append(tmpList1[i])\n",
    "    i=i+1  \n",
    "    \n",
    "yList2 = []\n",
    "for i in range(0,len(tmpList2)):\n",
    "    if tmpList2[i] != 2:\n",
    "        tmpList2[i] = 1\n",
    "    elif  tmpList2[i] == 2:\n",
    "        tmpList2[i] = 0\n",
    "    yList2.append(tmpList2[i])\n",
    "    i=i+1  \n",
    "    \n",
    "yList3 = []\n",
    "for i in range(0,len(tmpList3)):\n",
    "    if tmpList3[i] != 3:\n",
    "        tmpList3[i] = 1\n",
    "    elif  tmpList3[i] == 3:\n",
    "        tmpList3[i] = 0\n",
    "    yList3.append(tmpList3[i])\n",
    "    i=i+1  \n",
    "    \n",
    "yList4 = []\n",
    "for i in range(0,len(tmpList4)):\n",
    "    if tmpList4[i] != 4:\n",
    "        tmpList4[i] = 1\n",
    "    elif  tmpList4[i] == 4:\n",
    "        tmpList4[i] = 0\n",
    "    yList4.append(tmpList4[i])\n",
    "    i=i+1  \n",
    "    \n",
    "yList5 = []\n",
    "for i in range(0,len(tmpList5)):\n",
    "    if tmpList5[i] != 5:\n",
    "        tmpList5[i] = 1\n",
    "    elif  tmpList5[i] == 5:\n",
    "        tmpList5[i] = 0\n",
    "    yList5.append(tmpList5[i])\n",
    "    i=i+1  \n",
    "    \n",
    "yList6 = []\n",
    "for i in range(0,len(tmpList6)):\n",
    "    if tmpList6[i] != 6:\n",
    "        tmpList6[i] = 1\n",
    "    elif  tmpList6[i] == 6:\n",
    "        tmpList6[i] = 0\n",
    "    yList6.append(tmpList6[i])\n",
    "    i=i+1  \n",
    "    \n",
    "yList7 = []\n",
    "for i in range(0,len(tmpList7)):\n",
    "    if tmpList7[i] != 7:\n",
    "        tmpList7[i] = 1\n",
    "    elif  tmpList7[i] == 7:\n",
    "        tmpList7[i] = 0\n",
    "    yList7.append(tmpList7[i])\n",
    "    i=i+1  \n",
    "    \n",
    "ytestList0 = []\n",
    "for i in range(0,len(tmptestList0)):\n",
    "    if tmptestList0[i] != 0:\n",
    "        tmptestList0[i] = 1\n",
    "    ytestList0.append(tmptestList0[i])\n",
    "    i=i+1        \n",
    "    \n",
    "ytestList1 = []\n",
    "for i in range(0,len(tmptestList1)):\n",
    "    if tmptestList1[i] != 1:\n",
    "        tmptestList1[i] = 1\n",
    "    elif  tmptestList1[i] == 1:\n",
    "        tmptestList1[i] = 0\n",
    "    ytestList1.append(tmptestList1[i])\n",
    "    i=i+1  \n",
    "    \n",
    "ytestList2 = []\n",
    "for i in range(0,len(tmptestList2)):\n",
    "    if tmptestList2[i] != 2:\n",
    "        tmptestList2[i] = 1\n",
    "    elif  tmptestList2[i] == 2:\n",
    "        tmptestList2[i] = 0\n",
    "    ytestList2.append(tmptestList2[i])\n",
    "    i=i+1  \n",
    "    \n",
    "ytestList3 = []\n",
    "for i in range(0,len(tmptestList3)):\n",
    "    if tmptestList3[i] != 3:\n",
    "        tmptestList3[i] = 1\n",
    "    elif  tmptestList3[i] == 3:\n",
    "        tmptestList3[i] = 0\n",
    "    ytestList3.append(tmptestList3[i])\n",
    "    i=i+1  \n",
    "    \n",
    "ytestList4 = []\n",
    "for i in range(0,len(tmptestList4)):\n",
    "    if tmptestList4[i] != 4:\n",
    "        tmptestList4[i] = 1\n",
    "    elif  tmptestList4[i] == 4:\n",
    "        tmptestList4[i] = 0\n",
    "    ytestList4.append(tmptestList4[i])\n",
    "    i=i+1  \n",
    "    \n",
    "ytestList5 = []\n",
    "for i in range(0,len(tmptestList5)):\n",
    "    if tmptestList5[i] != 5:\n",
    "        tmptestList5[i] = 1\n",
    "    elif  tmptestList5[i] == 5:\n",
    "        tmptestList5[i] = 0\n",
    "    ytestList5.append(tmptestList5[i])\n",
    "    i=i+1  \n",
    "    \n",
    "ytestList6 = []\n",
    "for i in range(0,len(tmptestList6)):\n",
    "    if tmptestList6[i] != 6:\n",
    "        tmptestList6[i] = 1\n",
    "    elif  tmptestList6[i] == 6:\n",
    "        tmptestList6[i] = 0\n",
    "    ytestList6.append(tmptestList6[i])\n",
    "    i=i+1  \n",
    "    \n",
    "ytestList7 = []\n",
    "for i in range(0,len(tmptestList7)):\n",
    "    if tmptestList7[i] != 7:\n",
    "        tmptestList7[i] = 1\n",
    "    elif  tmptestList7[i] == 7:\n",
    "        tmptestList7[i] = 0\n",
    "    ytestList7.append(tmptestList7[i])\n",
    "    i=i+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078ce6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "Y_train = y_trainArr\n",
    "Y_test = y_testArr\n",
    "Y_train_float = tf.cast(Y_train,dtype=tf.float32)\n",
    "Y_test_float = tf.cast(Y_test,dtype=tf.float32)\n",
    "yList0tf = tf.cast(np.array(yList0),dtype=tf.float32)\n",
    "yList1tf = tf.cast(np.array(yList1),dtype=tf.float32)\n",
    "yList2tf = tf.cast(np.array(yList2),dtype=tf.float32)\n",
    "yList3tf = tf.cast(np.array(yList3),dtype=tf.float32)\n",
    "yList4tf = tf.cast(np.array(yList4),dtype=tf.float32)\n",
    "yList5tf = tf.cast(np.array(yList5),dtype=tf.float32)\n",
    "yList6tf = tf.cast(np.array(yList6),dtype=tf.float32)\n",
    "yList7tf = tf.cast(np.array(yList7),dtype=tf.float32)\n",
    "ytestList0tf = tf.cast(np.array(ytestList0),dtype=tf.float32)\n",
    "ytestList1tf = tf.cast(np.array(ytestList1),dtype=tf.float32)\n",
    "ytestList2tf = tf.cast(np.array(ytestList2),dtype=tf.float32)\n",
    "ytestList3tf = tf.cast(np.array(ytestList3),dtype=tf.float32)\n",
    "ytestList4tf = tf.cast(np.array(ytestList4),dtype=tf.float32)\n",
    "ytestList5tf = tf.cast(np.array(ytestList5),dtype=tf.float32)\n",
    "ytestList6tf = tf.cast(np.array(ytestList6),dtype=tf.float32)\n",
    "ytestList7tf = tf.cast(np.array(ytestList7),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749eba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM0Weights = np.load(\"tmp_LSTM0Weights.npy\",allow_pickle=True)\n",
    "attention0Weights = np.load(\"tmp_attention0Weights.npy\",allow_pickle=True)\n",
    "LSTM1Weights = np.load(\"tmp_LSTM1Weights.npy\",allow_pickle=True)\n",
    "attention1Weights = np.load(\"tmp_attention1Weights.npy\",allow_pickle=True)\n",
    "LSTM2Weights = np.load(\"tmp_LSTM2Weights.npy\",allow_pickle=True)\n",
    "attention2Weights = np.load(\"tmp_attention2Weights.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "053065fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp (InputLayer)                [(None, 295, 200)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 295, 200, 1)  0           inp[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 295, 200, 1)  2           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 295, 200)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 200, 295)     0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 200, 128)     184320      permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_3 (SeqSelfAt (None, None, 128)    8257        bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 64)     41216       seq_self_attention_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_4 (SeqSelfAt (None, None, 64)     4161        bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 32)     10368       seq_self_attention_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_5 (SeqSelfAt (None, 200, 32)      2113        bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6400)         0           seq_self_attention_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 400)          2560400     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 200)          80200       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           12864       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           528         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 8)            136         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            9           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y_pred (Activation)             (None, 8)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y0_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y1_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y2_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y3_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y4_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y5_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y6_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y7_pred (Activation)            (None, 1)            0           dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,906,654\n",
      "Trainable params: 2,906,654\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(295,200), name='inp')\n",
    "tmp = Reshape([295,200,1])(inp)\n",
    "tmp=Conv2D(1,(1,1),padding = 'valid',activation = 'relu',strides = 1)(tmp)\n",
    "tmp=Reshape([295,200])(tmp)\n",
    "tmp=Permute([2,1])(tmp)\n",
    "tmp=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64,activation = 'tanh',return_sequences=True))(tmp)\n",
    "tmp=SeqSelfAttention(attention_activation='softmax')(tmp)\n",
    "tmp=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=32,activation = 'tanh',return_sequences=True))(tmp)\n",
    "tmp=SeqSelfAttention(attention_activation='softmax')(tmp)\n",
    "tmp=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=16,activation = 'tanh',return_sequences=True))(tmp)\n",
    "tmp=SeqSelfAttention(attention_activation='softmax')(tmp)\n",
    "tmp.set_shape([None,200,32])\n",
    "tmp=Flatten()(tmp)\n",
    "tmp = Dense(400)(tmp)\n",
    "tmp = Dense(200)(tmp)\n",
    "tmp = Dense(64)(tmp)\n",
    "tmp = Dense(32)(tmp)\n",
    "tmp = Dense(16)(tmp)\n",
    "tmp = Dense(8)(tmp)\n",
    "y_pred=Activation('softmax',name='y_pred')(tmp)\n",
    "tmp1 = Dense(1)(tmp)\n",
    "y0_pred=Activation('sigmoid',name='y0_pred')(tmp1)\n",
    "y1_pred=Activation('sigmoid',name='y1_pred')(tmp1)\n",
    "y2_pred=Activation('sigmoid',name='y2_pred')(tmp1)\n",
    "y3_pred=Activation('sigmoid',name='y3_pred')(tmp1)\n",
    "y4_pred=Activation('sigmoid',name='y4_pred')(tmp1)\n",
    "y5_pred=Activation('sigmoid',name='y5_pred')(tmp1)\n",
    "y6_pred=Activation('sigmoid',name='y6_pred')(tmp1)\n",
    "y7_pred=Activation('sigmoid',name='y7_pred')(tmp1)\n",
    "model = Model(inputs=[inp],outputs=[y_pred,y0_pred,y1_pred,y2_pred,y3_pred,y4_pred,y5_pred,y6_pred,y7_pred])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb9f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[5].set_weights(LSTM0Weights)\n",
    "model.layers[6].set_weights(attention0Weights)\n",
    "model.layers[7].set_weights(LSTM1Weights)\n",
    "model.layers[8].set_weights(attention1Weights)\n",
    "model.layers[9].set_weights(LSTM2Weights)\n",
    "model.layers[10].set_weights(attention2Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997fb597",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 23s 798ms/step - loss: 5.4610 - y_pred_loss: 1.6976 - y0_pred_loss: 0.7171 - y1_pred_loss: 0.3369 - y2_pred_loss: 0.4524 - y3_pred_loss: 0.3757 - y4_pred_loss: 0.2889 - y5_pred_loss: 0.7795 - y6_pred_loss: 0.3477 - y7_pred_loss: 0.4652 - y_pred_categorical_accuracy: 0.4344 - y0_pred_binary_accuracy: 0.6300 - y1_pred_binary_accuracy: 0.8271 - y2_pred_binary_accuracy: 0.7840 - y3_pred_binary_accuracy: 0.7866 - y4_pred_binary_accuracy: 0.8447 - y5_pred_binary_accuracy: 0.6588 - y6_pred_binary_accuracy: 0.8239 - y7_pred_binary_accuracy: 0.7576 - val_loss: 4.0620 - val_y_pred_loss: 1.0130 - val_y0_pred_loss: 0.7452 - val_y1_pred_loss: 0.2240 - val_y2_pred_loss: 0.3395 - val_y3_pred_loss: 0.2822 - val_y4_pred_loss: 0.1570 - val_y5_pred_loss: 0.6669 - val_y6_pred_loss: 0.2335 - val_y7_pred_loss: 0.4008 - val_y_pred_categorical_accuracy: 0.7025 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 11s 668ms/step - loss: 3.8903 - y_pred_loss: 0.8363 - y0_pred_loss: 0.7033 - y1_pred_loss: 0.2233 - y2_pred_loss: 0.3526 - y3_pred_loss: 0.2735 - y4_pred_loss: 0.1597 - y5_pred_loss: 0.7128 - y6_pred_loss: 0.2378 - y7_pred_loss: 0.3911 - y_pred_categorical_accuracy: 0.7237 - y0_pred_binary_accuracy: 0.7132 - y1_pred_binary_accuracy: 0.9588 - y2_pred_binary_accuracy: 0.9009 - y3_pred_binary_accuracy: 0.9234 - y4_pred_binary_accuracy: 0.9930 - y5_pred_binary_accuracy: 0.6862 - y6_pred_binary_accuracy: 0.9549 - y7_pred_binary_accuracy: 0.8697 - val_loss: 3.8497 - val_y_pred_loss: 0.8210 - val_y0_pred_loss: 0.7260 - val_y1_pred_loss: 0.2237 - val_y2_pred_loss: 0.3206 - val_y3_pred_loss: 0.2719 - val_y4_pred_loss: 0.1609 - val_y5_pred_loss: 0.7215 - val_y6_pred_loss: 0.2267 - val_y7_pred_loss: 0.3773 - val_y_pred_categorical_accuracy: 0.7363 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 12s 727ms/step - loss: 3.6764 - y_pred_loss: 0.6427 - y0_pred_loss: 0.6955 - y1_pred_loss: 0.2295 - y2_pred_loss: 0.3288 - y3_pred_loss: 0.2810 - y4_pred_loss: 0.1575 - y5_pred_loss: 0.7313 - y6_pred_loss: 0.2299 - y7_pred_loss: 0.3803 - y_pred_categorical_accuracy: 0.7837 - y0_pred_binary_accuracy: 0.7133 - y1_pred_binary_accuracy: 0.9559 - y2_pred_binary_accuracy: 0.9029 - y3_pred_binary_accuracy: 0.9187 - y4_pred_binary_accuracy: 0.9925 - y5_pred_binary_accuracy: 0.6877 - y6_pred_binary_accuracy: 0.9563 - y7_pred_binary_accuracy: 0.8727 - val_loss: 3.8098 - val_y_pred_loss: 0.7917 - val_y0_pred_loss: 0.7039 - val_y1_pred_loss: 0.2187 - val_y2_pred_loss: 0.3212 - val_y3_pred_loss: 0.2808 - val_y4_pred_loss: 0.1536 - val_y5_pred_loss: 0.7295 - val_y6_pred_loss: 0.2238 - val_y7_pred_loss: 0.3865 - val_y_pred_categorical_accuracy: 0.7527 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 12s 731ms/step - loss: 3.5920 - y_pred_loss: 0.5727 - y0_pred_loss: 0.7007 - y1_pred_loss: 0.2198 - y2_pred_loss: 0.3282 - y3_pred_loss: 0.2748 - y4_pred_loss: 0.1504 - y5_pred_loss: 0.7316 - y6_pred_loss: 0.2207 - y7_pred_loss: 0.3931 - y_pred_categorical_accuracy: 0.8034 - y0_pred_binary_accuracy: 0.7137 - y1_pred_binary_accuracy: 0.9566 - y2_pred_binary_accuracy: 0.8995 - y3_pred_binary_accuracy: 0.9249 - y4_pred_binary_accuracy: 0.9908 - y5_pred_binary_accuracy: 0.6888 - y6_pred_binary_accuracy: 0.9575 - y7_pred_binary_accuracy: 0.8682 - val_loss: 3.7390 - val_y_pred_loss: 0.7177 - val_y0_pred_loss: 0.7048 - val_y1_pred_loss: 0.2091 - val_y2_pred_loss: 0.3201 - val_y3_pred_loss: 0.2781 - val_y4_pred_loss: 0.1396 - val_y5_pred_loss: 0.7684 - val_y6_pred_loss: 0.2132 - val_y7_pred_loss: 0.3880 - val_y_pred_categorical_accuracy: 0.7710 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 13s 742ms/step - loss: 3.5338 - y_pred_loss: 0.5126 - y0_pred_loss: 0.7126 - y1_pred_loss: 0.2152 - y2_pred_loss: 0.3226 - y3_pred_loss: 0.2758 - y4_pred_loss: 0.1509 - y5_pred_loss: 0.7375 - y6_pred_loss: 0.2185 - y7_pred_loss: 0.3881 - y_pred_categorical_accuracy: 0.8193 - y0_pred_binary_accuracy: 0.7026 - y1_pred_binary_accuracy: 0.9578 - y2_pred_binary_accuracy: 0.9026 - y3_pred_binary_accuracy: 0.9264 - y4_pred_binary_accuracy: 0.9901 - y5_pred_binary_accuracy: 0.6919 - y6_pred_binary_accuracy: 0.9577 - y7_pred_binary_accuracy: 0.8708 - val_loss: 3.7598 - val_y_pred_loss: 0.7426 - val_y0_pred_loss: 0.7014 - val_y1_pred_loss: 0.2203 - val_y2_pred_loss: 0.3206 - val_y3_pred_loss: 0.2792 - val_y4_pred_loss: 0.1495 - val_y5_pred_loss: 0.7431 - val_y6_pred_loss: 0.2176 - val_y7_pred_loss: 0.3857 - val_y_pred_categorical_accuracy: 0.7757 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 12s 728ms/step - loss: 3.5148 - y_pred_loss: 0.4960 - y0_pred_loss: 0.6970 - y1_pred_loss: 0.2187 - y2_pred_loss: 0.3272 - y3_pred_loss: 0.2776 - y4_pred_loss: 0.1485 - y5_pred_loss: 0.7478 - y6_pred_loss: 0.2148 - y7_pred_loss: 0.3873 - y_pred_categorical_accuracy: 0.8239 - y0_pred_binary_accuracy: 0.7091 - y1_pred_binary_accuracy: 0.9562 - y2_pred_binary_accuracy: 0.9006 - y3_pred_binary_accuracy: 0.9269 - y4_pred_binary_accuracy: 0.9919 - y5_pred_binary_accuracy: 0.6857 - y6_pred_binary_accuracy: 0.9586 - y7_pred_binary_accuracy: 0.8710 - val_loss: 3.7387 - val_y_pred_loss: 0.7216 - val_y0_pred_loss: 0.7064 - val_y1_pred_loss: 0.2151 - val_y2_pred_loss: 0.3285 - val_y3_pred_loss: 0.2810 - val_y4_pred_loss: 0.1500 - val_y5_pred_loss: 0.7308 - val_y6_pred_loss: 0.2190 - val_y7_pred_loss: 0.3864 - val_y_pred_categorical_accuracy: 0.7785 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 12s 728ms/step - loss: 3.5041 - y_pred_loss: 0.4869 - y0_pred_loss: 0.6879 - y1_pred_loss: 0.2150 - y2_pred_loss: 0.3294 - y3_pred_loss: 0.2903 - y4_pred_loss: 0.1482 - y5_pred_loss: 0.7368 - y6_pred_loss: 0.2224 - y7_pred_loss: 0.3872 - y_pred_categorical_accuracy: 0.8300 - y0_pred_binary_accuracy: 0.7155 - y1_pred_binary_accuracy: 0.9579 - y2_pred_binary_accuracy: 0.9000 - y3_pred_binary_accuracy: 0.9204 - y4_pred_binary_accuracy: 0.9928 - y5_pred_binary_accuracy: 0.6885 - y6_pred_binary_accuracy: 0.9550 - y7_pred_binary_accuracy: 0.8700 - val_loss: 3.7410 - val_y_pred_loss: 0.7198 - val_y0_pred_loss: 0.6999 - val_y1_pred_loss: 0.2089 - val_y2_pred_loss: 0.3222 - val_y3_pred_loss: 0.2769 - val_y4_pred_loss: 0.1400 - val_y5_pred_loss: 0.7803 - val_y6_pred_loss: 0.2095 - val_y7_pred_loss: 0.3836 - val_y_pred_categorical_accuracy: 0.7766 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "17/17 [==============================] - 12s 729ms/step - loss: 3.5224 - y_pred_loss: 0.5002 - y0_pred_loss: 0.6925 - y1_pred_loss: 0.2192 - y2_pred_loss: 0.3300 - y3_pred_loss: 0.2833 - y4_pred_loss: 0.1470 - y5_pred_loss: 0.7538 - y6_pred_loss: 0.2133 - y7_pred_loss: 0.3832 - y_pred_categorical_accuracy: 0.8194 - y0_pred_binary_accuracy: 0.7116 - y1_pred_binary_accuracy: 0.9561 - y2_pred_binary_accuracy: 0.9004 - y3_pred_binary_accuracy: 0.9217 - y4_pred_binary_accuracy: 0.9925 - y5_pred_binary_accuracy: 0.6844 - y6_pred_binary_accuracy: 0.9597 - y7_pred_binary_accuracy: 0.8729 - val_loss: 3.7877 - val_y_pred_loss: 0.7586 - val_y0_pred_loss: 0.7324 - val_y1_pred_loss: 0.2172 - val_y2_pred_loss: 0.3335 - val_y3_pred_loss: 0.2664 - val_y4_pred_loss: 0.1560 - val_y5_pred_loss: 0.7323 - val_y6_pred_loss: 0.2225 - val_y7_pred_loss: 0.3688 - val_y_pred_categorical_accuracy: 0.7733 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 12s 733ms/step - loss: 3.5043 - y_pred_loss: 0.4769 - y0_pred_loss: 0.7029 - y1_pred_loss: 0.2168 - y2_pred_loss: 0.3258 - y3_pred_loss: 0.2806 - y4_pred_loss: 0.1475 - y5_pred_loss: 0.7568 - y6_pred_loss: 0.2172 - y7_pred_loss: 0.3798 - y_pred_categorical_accuracy: 0.8309 - y0_pred_binary_accuracy: 0.7102 - y1_pred_binary_accuracy: 0.9555 - y2_pred_binary_accuracy: 0.9033 - y3_pred_binary_accuracy: 0.9226 - y4_pred_binary_accuracy: 0.9930 - y5_pred_binary_accuracy: 0.6854 - y6_pred_binary_accuracy: 0.9578 - y7_pred_binary_accuracy: 0.8723 - val_loss: 3.7385 - val_y_pred_loss: 0.7186 - val_y0_pred_loss: 0.6763 - val_y1_pred_loss: 0.2167 - val_y2_pred_loss: 0.3259 - val_y3_pred_loss: 0.2843 - val_y4_pred_loss: 0.1552 - val_y5_pred_loss: 0.7639 - val_y6_pred_loss: 0.2174 - val_y7_pred_loss: 0.3801 - val_y_pred_categorical_accuracy: 0.7874 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 12s 733ms/step - loss: 3.4754 - y_pred_loss: 0.4562 - y0_pred_loss: 0.7033 - y1_pred_loss: 0.2171 - y2_pred_loss: 0.3232 - y3_pred_loss: 0.2808 - y4_pred_loss: 0.1510 - y5_pred_loss: 0.7416 - y6_pred_loss: 0.2149 - y7_pred_loss: 0.3872 - y_pred_categorical_accuracy: 0.8403 - y0_pred_binary_accuracy: 0.7033 - y1_pred_binary_accuracy: 0.9583 - y2_pred_binary_accuracy: 0.9022 - y3_pred_binary_accuracy: 0.9256 - y4_pred_binary_accuracy: 0.9919 - y5_pred_binary_accuracy: 0.6893 - y6_pred_binary_accuracy: 0.9589 - y7_pred_binary_accuracy: 0.8704 - val_loss: 3.7535 - val_y_pred_loss: 0.7360 - val_y0_pred_loss: 0.6846 - val_y1_pred_loss: 0.2137 - val_y2_pred_loss: 0.3256 - val_y3_pred_loss: 0.2789 - val_y4_pred_loss: 0.1465 - val_y5_pred_loss: 0.7679 - val_y6_pred_loss: 0.2152 - val_y7_pred_loss: 0.3850 - val_y_pred_categorical_accuracy: 0.7762 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 12s 725ms/step - loss: 3.4586 - y_pred_loss: 0.4417 - y0_pred_loss: 0.6879 - y1_pred_loss: 0.2125 - y2_pred_loss: 0.3276 - y3_pred_loss: 0.2852 - y4_pred_loss: 0.1495 - y5_pred_loss: 0.7464 - y6_pred_loss: 0.2187 - y7_pred_loss: 0.3890 - y_pred_categorical_accuracy: 0.8419 - y0_pred_binary_accuracy: 0.7146 - y1_pred_binary_accuracy: 0.9594 - y2_pred_binary_accuracy: 0.9015 - y3_pred_binary_accuracy: 0.9217 - y4_pred_binary_accuracy: 0.9918 - y5_pred_binary_accuracy: 0.6848 - y6_pred_binary_accuracy: 0.9568 - y7_pred_binary_accuracy: 0.8694 - val_loss: 3.7771 - val_y_pred_loss: 0.7573 - val_y0_pred_loss: 0.7013 - val_y1_pred_loss: 0.2218 - val_y2_pred_loss: 0.3304 - val_y3_pred_loss: 0.2831 - val_y4_pred_loss: 0.1597 - val_y5_pred_loss: 0.7126 - val_y6_pred_loss: 0.2254 - val_y7_pred_loss: 0.3853 - val_y_pred_categorical_accuracy: 0.7738 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 12s 728ms/step - loss: 3.4567 - y_pred_loss: 0.4389 - y0_pred_loss: 0.6979 - y1_pred_loss: 0.2098 - y2_pred_loss: 0.3240 - y3_pred_loss: 0.2767 - y4_pred_loss: 0.1487 - y5_pred_loss: 0.7558 - y6_pred_loss: 0.2178 - y7_pred_loss: 0.3873 - y_pred_categorical_accuracy: 0.8405 - y0_pred_binary_accuracy: 0.7114 - y1_pred_binary_accuracy: 0.9610 - y2_pred_binary_accuracy: 0.9022 - y3_pred_binary_accuracy: 0.9265 - y4_pred_binary_accuracy: 0.9931 - y5_pred_binary_accuracy: 0.6781 - y6_pred_binary_accuracy: 0.9578 - y7_pred_binary_accuracy: 0.8699 - val_loss: 3.7873 - val_y_pred_loss: 0.7709 - val_y0_pred_loss: 0.7051 - val_y1_pred_loss: 0.2169 - val_y2_pred_loss: 0.3261 - val_y3_pred_loss: 0.2754 - val_y4_pred_loss: 0.1518 - val_y5_pred_loss: 0.7426 - val_y6_pred_loss: 0.2190 - val_y7_pred_loss: 0.3796 - val_y_pred_categorical_accuracy: 0.7719 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 12s 732ms/step - loss: 3.4746 - y_pred_loss: 0.4580 - y0_pred_loss: 0.6959 - y1_pred_loss: 0.2147 - y2_pred_loss: 0.3233 - y3_pred_loss: 0.2781 - y4_pred_loss: 0.1496 - y5_pred_loss: 0.7535 - y6_pred_loss: 0.2202 - y7_pred_loss: 0.3815 - y_pred_categorical_accuracy: 0.8370 - y0_pred_binary_accuracy: 0.7108 - y1_pred_binary_accuracy: 0.9582 - y2_pred_binary_accuracy: 0.9037 - y3_pred_binary_accuracy: 0.9255 - y4_pred_binary_accuracy: 0.9920 - y5_pred_binary_accuracy: 0.6819 - y6_pred_binary_accuracy: 0.9556 - y7_pred_binary_accuracy: 0.8724 - val_loss: 3.7655 - val_y_pred_loss: 0.7484 - val_y0_pred_loss: 0.7020 - val_y1_pred_loss: 0.2164 - val_y2_pred_loss: 0.3239 - val_y3_pred_loss: 0.2755 - val_y4_pred_loss: 0.1489 - val_y5_pred_loss: 0.7566 - val_y6_pred_loss: 0.2151 - val_y7_pred_loss: 0.3788 - val_y_pred_categorical_accuracy: 0.7841 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 12s 730ms/step - loss: 3.4565 - y_pred_loss: 0.4400 - y0_pred_loss: 0.6916 - y1_pred_loss: 0.2182 - y2_pred_loss: 0.3259 - y3_pred_loss: 0.2756 - y4_pred_loss: 0.1463 - y5_pred_loss: 0.7575 - y6_pred_loss: 0.2138 - y7_pred_loss: 0.3875 - y_pred_categorical_accuracy: 0.8451 - y0_pred_binary_accuracy: 0.7140 - y1_pred_binary_accuracy: 0.9562 - y2_pred_binary_accuracy: 0.9019 - y3_pred_binary_accuracy: 0.9263 - y4_pred_binary_accuracy: 0.9933 - y5_pred_binary_accuracy: 0.6802 - y6_pred_binary_accuracy: 0.9591 - y7_pred_binary_accuracy: 0.8689 - val_loss: 3.7838 - val_y_pred_loss: 0.7647 - val_y0_pred_loss: 0.7051 - val_y1_pred_loss: 0.2212 - val_y2_pred_loss: 0.3288 - val_y3_pred_loss: 0.2812 - val_y4_pred_loss: 0.1468 - val_y5_pred_loss: 0.7320 - val_y6_pred_loss: 0.2147 - val_y7_pred_loss: 0.3894 - val_y_pred_categorical_accuracy: 0.7884 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "17/17 [==============================] - 12s 735ms/step - loss: 3.4652 - y_pred_loss: 0.4464 - y0_pred_loss: 0.7058 - y1_pred_loss: 0.2158 - y2_pred_loss: 0.3339 - y3_pred_loss: 0.2816 - y4_pred_loss: 0.1528 - y5_pred_loss: 0.7346 - y6_pred_loss: 0.2121 - y7_pred_loss: 0.3823 - y_pred_categorical_accuracy: 0.8415 - y0_pred_binary_accuracy: 0.7070 - y1_pred_binary_accuracy: 0.9582 - y2_pred_binary_accuracy: 0.8992 - y3_pred_binary_accuracy: 0.9243 - y4_pred_binary_accuracy: 0.9900 - y5_pred_binary_accuracy: 0.6879 - y6_pred_binary_accuracy: 0.9599 - y7_pred_binary_accuracy: 0.8735 - val_loss: 3.7895 - val_y_pred_loss: 0.7721 - val_y0_pred_loss: 0.6839 - val_y1_pred_loss: 0.2163 - val_y2_pred_loss: 0.3265 - val_y3_pred_loss: 0.2840 - val_y4_pred_loss: 0.1494 - val_y5_pred_loss: 0.7525 - val_y6_pred_loss: 0.2160 - val_y7_pred_loss: 0.3887 - val_y_pred_categorical_accuracy: 0.7715 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 12s 730ms/step - loss: 3.4516 - y_pred_loss: 0.4336 - y0_pred_loss: 0.6931 - y1_pred_loss: 0.2154 - y2_pred_loss: 0.3255 - y3_pred_loss: 0.2801 - y4_pred_loss: 0.1524 - y5_pred_loss: 0.7532 - y6_pred_loss: 0.2168 - y7_pred_loss: 0.3815 - y_pred_categorical_accuracy: 0.8462 - y0_pred_binary_accuracy: 0.7117 - y1_pred_binary_accuracy: 0.9582 - y2_pred_binary_accuracy: 0.9025 - y3_pred_binary_accuracy: 0.9247 - y4_pred_binary_accuracy: 0.9912 - y5_pred_binary_accuracy: 0.6804 - y6_pred_binary_accuracy: 0.9583 - y7_pred_binary_accuracy: 0.8730 - val_loss: 3.7551 - val_y_pred_loss: 0.7388 - val_y0_pred_loss: 0.6950 - val_y1_pred_loss: 0.2172 - val_y2_pred_loss: 0.3218 - val_y3_pred_loss: 0.2823 - val_y4_pred_loss: 0.1523 - val_y5_pred_loss: 0.7434 - val_y6_pred_loss: 0.2190 - val_y7_pred_loss: 0.3853 - val_y_pred_categorical_accuracy: 0.7926 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 13s 742ms/step - loss: 3.4423 - y_pred_loss: 0.4258 - y0_pred_loss: 0.6886 - y1_pred_loss: 0.2181 - y2_pred_loss: 0.3289 - y3_pred_loss: 0.2778 - y4_pred_loss: 0.1494 - y5_pred_loss: 0.7481 - y6_pred_loss: 0.2186 - y7_pred_loss: 0.3870 - y_pred_categorical_accuracy: 0.8481 - y0_pred_binary_accuracy: 0.7150 - y1_pred_binary_accuracy: 0.9567 - y2_pred_binary_accuracy: 0.8989 - y3_pred_binary_accuracy: 0.9258 - y4_pred_binary_accuracy: 0.9921 - y5_pred_binary_accuracy: 0.6844 - y6_pred_binary_accuracy: 0.9567 - y7_pred_binary_accuracy: 0.8703 - val_loss: 3.7754 - val_y_pred_loss: 0.7591 - val_y0_pred_loss: 0.6903 - val_y1_pred_loss: 0.2167 - val_y2_pred_loss: 0.3304 - val_y3_pred_loss: 0.2825 - val_y4_pred_loss: 0.1518 - val_y5_pred_loss: 0.7398 - val_y6_pred_loss: 0.2185 - val_y7_pred_loss: 0.3863 - val_y_pred_categorical_accuracy: 0.7921 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 13s 737ms/step - loss: 3.4466 - y_pred_loss: 0.4297 - y0_pred_loss: 0.6953 - y1_pred_loss: 0.2154 - y2_pred_loss: 0.3232 - y3_pred_loss: 0.2852 - y4_pred_loss: 0.1548 - y5_pred_loss: 0.7436 - y6_pred_loss: 0.2177 - y7_pred_loss: 0.3818 - y_pred_categorical_accuracy: 0.8471 - y0_pred_binary_accuracy: 0.7113 - y1_pred_binary_accuracy: 0.9585 - y2_pred_binary_accuracy: 0.9031 - y3_pred_binary_accuracy: 0.9225 - y4_pred_binary_accuracy: 0.9899 - y5_pred_binary_accuracy: 0.6839 - y6_pred_binary_accuracy: 0.9574 - y7_pred_binary_accuracy: 0.8733 - val_loss: 3.7859 - val_y_pred_loss: 0.7686 - val_y0_pred_loss: 0.6867 - val_y1_pred_loss: 0.2179 - val_y2_pred_loss: 0.3305 - val_y3_pred_loss: 0.2844 - val_y4_pred_loss: 0.1537 - val_y5_pred_loss: 0.7377 - val_y6_pred_loss: 0.2191 - val_y7_pred_loss: 0.3872 - val_y_pred_categorical_accuracy: 0.7851 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 12s 729ms/step - loss: 3.4409 - y_pred_loss: 0.4235 - y0_pred_loss: 0.7065 - y1_pred_loss: 0.2182 - y2_pred_loss: 0.3274 - y3_pred_loss: 0.2799 - y4_pred_loss: 0.1496 - y5_pred_loss: 0.7384 - y6_pred_loss: 0.2191 - y7_pred_loss: 0.3783 - y_pred_categorical_accuracy: 0.8498 - y0_pred_binary_accuracy: 0.7049 - y1_pred_binary_accuracy: 0.9564 - y2_pred_binary_accuracy: 0.9007 - y3_pred_binary_accuracy: 0.9253 - y4_pred_binary_accuracy: 0.9919 - y5_pred_binary_accuracy: 0.6901 - y6_pred_binary_accuracy: 0.9561 - y7_pred_binary_accuracy: 0.8746 - val_loss: 3.7745 - val_y_pred_loss: 0.7574 - val_y0_pred_loss: 0.6896 - val_y1_pred_loss: 0.2157 - val_y2_pred_loss: 0.3266 - val_y3_pred_loss: 0.2750 - val_y4_pred_loss: 0.1507 - val_y5_pred_loss: 0.7612 - val_y6_pred_loss: 0.2175 - val_y7_pred_loss: 0.3809 - val_y_pred_categorical_accuracy: 0.7954 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 13s 738ms/step - loss: 3.4104 - y_pred_loss: 0.3936 - y0_pred_loss: 0.6933 - y1_pred_loss: 0.2178 - y2_pred_loss: 0.3323 - y3_pred_loss: 0.2718 - y4_pred_loss: 0.1517 - y5_pred_loss: 0.7484 - y6_pred_loss: 0.2206 - y7_pred_loss: 0.3808 - y_pred_categorical_accuracy: 0.8615 - y0_pred_binary_accuracy: 0.7116 - y1_pred_binary_accuracy: 0.9570 - y2_pred_binary_accuracy: 0.8987 - y3_pred_binary_accuracy: 0.9287 - y4_pred_binary_accuracy: 0.9909 - y5_pred_binary_accuracy: 0.6847 - y6_pred_binary_accuracy: 0.9549 - y7_pred_binary_accuracy: 0.8734 - val_loss: 3.8214 - val_y_pred_loss: 0.8035 - val_y0_pred_loss: 0.7105 - val_y1_pred_loss: 0.2122 - val_y2_pred_loss: 0.3169 - val_y3_pred_loss: 0.2815 - val_y4_pred_loss: 0.1483 - val_y5_pred_loss: 0.7479 - val_y6_pred_loss: 0.2159 - val_y7_pred_loss: 0.3846 - val_y_pred_categorical_accuracy: 0.7837 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 12s 725ms/step - loss: 3.4364 - y_pred_loss: 0.4193 - y0_pred_loss: 0.6944 - y1_pred_loss: 0.2115 - y2_pred_loss: 0.3320 - y3_pred_loss: 0.2780 - y4_pred_loss: 0.1498 - y5_pred_loss: 0.7576 - y6_pred_loss: 0.2181 - y7_pred_loss: 0.3758 - y_pred_categorical_accuracy: 0.8508 - y0_pred_binary_accuracy: 0.7133 - y1_pred_binary_accuracy: 0.9597 - y2_pred_binary_accuracy: 0.8977 - y3_pred_binary_accuracy: 0.9257 - y4_pred_binary_accuracy: 0.9914 - y5_pred_binary_accuracy: 0.6790 - y6_pred_binary_accuracy: 0.9570 - y7_pred_binary_accuracy: 0.8761 - val_loss: 3.8128 - val_y_pred_loss: 0.7949 - val_y0_pred_loss: 0.6896 - val_y1_pred_loss: 0.2161 - val_y2_pred_loss: 0.3250 - val_y3_pred_loss: 0.2796 - val_y4_pred_loss: 0.1517 - val_y5_pred_loss: 0.7644 - val_y6_pred_loss: 0.2138 - val_y7_pred_loss: 0.3777 - val_y_pred_categorical_accuracy: 0.7888 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "17/17 [==============================] - 13s 737ms/step - loss: 3.4116 - y_pred_loss: 0.3943 - y0_pred_loss: 0.6894 - y1_pred_loss: 0.2199 - y2_pred_loss: 0.3322 - y3_pred_loss: 0.2758 - y4_pred_loss: 0.1488 - y5_pred_loss: 0.7427 - y6_pred_loss: 0.2175 - y7_pred_loss: 0.3909 - y_pred_categorical_accuracy: 0.8570 - y0_pred_binary_accuracy: 0.7121 - y1_pred_binary_accuracy: 0.9556 - y2_pred_binary_accuracy: 0.8988 - y3_pred_binary_accuracy: 0.9275 - y4_pred_binary_accuracy: 0.9924 - y5_pred_binary_accuracy: 0.6885 - y6_pred_binary_accuracy: 0.9570 - y7_pred_binary_accuracy: 0.8682 - val_loss: 3.8271 - val_y_pred_loss: 0.8101 - val_y0_pred_loss: 0.7061 - val_y1_pred_loss: 0.2187 - val_y2_pred_loss: 0.3278 - val_y3_pred_loss: 0.2815 - val_y4_pred_loss: 0.1520 - val_y5_pred_loss: 0.7318 - val_y6_pred_loss: 0.2162 - val_y7_pred_loss: 0.3829 - val_y_pred_categorical_accuracy: 0.7823 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 12s 730ms/step - loss: 3.4293 - y_pred_loss: 0.4117 - y0_pred_loss: 0.7005 - y1_pred_loss: 0.2139 - y2_pred_loss: 0.3279 - y3_pred_loss: 0.2825 - y4_pred_loss: 0.1489 - y5_pred_loss: 0.7356 - y6_pred_loss: 0.2228 - y7_pred_loss: 0.3856 - y_pred_categorical_accuracy: 0.8515 - y0_pred_binary_accuracy: 0.7089 - y1_pred_binary_accuracy: 0.9588 - y2_pred_binary_accuracy: 0.9003 - y3_pred_binary_accuracy: 0.9239 - y4_pred_binary_accuracy: 0.9922 - y5_pred_binary_accuracy: 0.6895 - y6_pred_binary_accuracy: 0.9543 - y7_pred_binary_accuracy: 0.8720 - val_loss: 3.8079 - val_y_pred_loss: 0.7886 - val_y0_pred_loss: 0.7083 - val_y1_pred_loss: 0.2124 - val_y2_pred_loss: 0.3282 - val_y3_pred_loss: 0.2794 - val_y4_pred_loss: 0.1435 - val_y5_pred_loss: 0.7523 - val_y6_pred_loss: 0.2109 - val_y7_pred_loss: 0.3845 - val_y_pred_categorical_accuracy: 0.7860 - val_y0_pred_binary_accuracy: 0.7086 - val_y1_pred_binary_accuracy: 0.9573 - val_y2_pred_binary_accuracy: 0.9010 - val_y3_pred_binary_accuracy: 0.9249 - val_y4_pred_binary_accuracy: 0.9911 - val_y5_pred_binary_accuracy: 0.6856 - val_y6_pred_binary_accuracy: 0.9568 - val_y7_pred_binary_accuracy: 0.8719\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 12s 694ms/step - loss: 3.4351 - y_pred_loss: 0.4171 - y0_pred_loss: 0.6955 - y1_pred_loss: 0.2184 - y2_pred_loss: 0.3194 - y3_pred_loss: 0.2759 - y4_pred_loss: 0.1498 - y5_pred_loss: 0.7620 - y6_pred_loss: 0.2202 - y7_pred_loss: 0.3769 - y_pred_categorical_accuracy: 0.8519 - y0_pred_binary_accuracy: 0.7101 - y1_pred_binary_accuracy: 0.9563 - y2_pred_binary_accuracy: 0.9062 - y3_pred_binary_accuracy: 0.9266 - y4_pred_binary_accuracy: 0.9914 - y5_pred_binary_accuracy: 0.6786 - y6_pred_binary_accuracy: 0.9556 - y7_pred_binary_accuracy: 0.8752 - val_loss: 3.8141 - val_y_pred_loss: 0.7898 - val_y0_pred_loss: 0.7384 - val_y1_pred_loss: 0.2046 - val_y2_pred_loss: 0.3225 - val_y3_pred_loss: 0.2727 - val_y4_pred_loss: 0.1370 - val_y5_pred_loss: 0.7619 - val_y6_pred_loss: 0.2062 - val_y7_pred_loss: 0.3809 - val_y_pred_categorical_accuracy: 0.7846 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 13s 738ms/step - loss: 3.4212 - y_pred_loss: 0.4011 - y0_pred_loss: 0.7141 - y1_pred_loss: 0.2102 - y2_pred_loss: 0.3205 - y3_pred_loss: 0.2690 - y4_pred_loss: 0.1507 - y5_pred_loss: 0.7611 - y6_pred_loss: 0.2160 - y7_pred_loss: 0.3784 - y_pred_categorical_accuracy: 0.8569 - y0_pred_binary_accuracy: 0.7058 - y1_pred_binary_accuracy: 0.9592 - y2_pred_binary_accuracy: 0.9029 - y3_pred_binary_accuracy: 0.9306 - y4_pred_binary_accuracy: 0.9906 - y5_pred_binary_accuracy: 0.6791 - y6_pred_binary_accuracy: 0.9572 - y7_pred_binary_accuracy: 0.8746 - val_loss: 3.7920 - val_y_pred_loss: 0.7757 - val_y0_pred_loss: 0.6998 - val_y1_pred_loss: 0.2147 - val_y2_pred_loss: 0.3280 - val_y3_pred_loss: 0.2752 - val_y4_pred_loss: 0.1491 - val_y5_pred_loss: 0.7584 - val_y6_pred_loss: 0.2140 - val_y7_pred_loss: 0.3772 - val_y_pred_categorical_accuracy: 0.7912 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 13s 736ms/step - loss: 3.4061 - y_pred_loss: 0.3877 - y0_pred_loss: 0.7071 - y1_pred_loss: 0.2153 - y2_pred_loss: 0.3305 - y3_pred_loss: 0.2745 - y4_pred_loss: 0.1499 - y5_pred_loss: 0.7505 - y6_pred_loss: 0.2168 - y7_pred_loss: 0.3739 - y_pred_categorical_accuracy: 0.8620 - y0_pred_binary_accuracy: 0.7045 - y1_pred_binary_accuracy: 0.9581 - y2_pred_binary_accuracy: 0.9001 - y3_pred_binary_accuracy: 0.9271 - y4_pred_binary_accuracy: 0.9925 - y5_pred_binary_accuracy: 0.6845 - y6_pred_binary_accuracy: 0.9574 - y7_pred_binary_accuracy: 0.8758 - val_loss: 3.7879 - val_y_pred_loss: 0.7682 - val_y0_pred_loss: 0.7098 - val_y1_pred_loss: 0.2121 - val_y2_pred_loss: 0.3200 - val_y3_pred_loss: 0.2782 - val_y4_pred_loss: 0.1427 - val_y5_pred_loss: 0.7519 - val_y6_pred_loss: 0.2146 - val_y7_pred_loss: 0.3904 - val_y_pred_categorical_accuracy: 0.7921 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 12s 730ms/step - loss: 3.4094 - y_pred_loss: 0.3888 - y0_pred_loss: 0.6970 - y1_pred_loss: 0.2214 - y2_pred_loss: 0.3309 - y3_pred_loss: 0.2721 - y4_pred_loss: 0.1464 - y5_pred_loss: 0.7560 - y6_pred_loss: 0.2131 - y7_pred_loss: 0.3838 - y_pred_categorical_accuracy: 0.8591 - y0_pred_binary_accuracy: 0.7144 - y1_pred_binary_accuracy: 0.9541 - y2_pred_binary_accuracy: 0.8993 - y3_pred_binary_accuracy: 0.9286 - y4_pred_binary_accuracy: 0.9925 - y5_pred_binary_accuracy: 0.6793 - y6_pred_binary_accuracy: 0.9588 - y7_pred_binary_accuracy: 0.8729 - val_loss: 3.7992 - val_y_pred_loss: 0.7772 - val_y0_pred_loss: 0.6825 - val_y1_pred_loss: 0.2257 - val_y2_pred_loss: 0.3256 - val_y3_pred_loss: 0.2798 - val_y4_pred_loss: 0.1593 - val_y5_pred_loss: 0.7349 - val_y6_pred_loss: 0.2285 - val_y7_pred_loss: 0.3858 - val_y_pred_categorical_accuracy: 0.7884 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 12s 721ms/step - loss: 3.4332 - y_pred_loss: 0.4138 - y0_pred_loss: 0.6900 - y1_pred_loss: 0.2207 - y2_pred_loss: 0.3238 - y3_pred_loss: 0.2943 - y4_pred_loss: 0.1526 - y5_pred_loss: 0.7462 - y6_pred_loss: 0.2110 - y7_pred_loss: 0.3808 - y_pred_categorical_accuracy: 0.8582 - y0_pred_binary_accuracy: 0.7129 - y1_pred_binary_accuracy: 0.9557 - y2_pred_binary_accuracy: 0.9019 - y3_pred_binary_accuracy: 0.9178 - y4_pred_binary_accuracy: 0.9912 - y5_pred_binary_accuracy: 0.6855 - y6_pred_binary_accuracy: 0.9614 - y7_pred_binary_accuracy: 0.8736 - val_loss: 3.7852 - val_y_pred_loss: 0.7663 - val_y0_pred_loss: 0.6946 - val_y1_pred_loss: 0.2178 - val_y2_pred_loss: 0.3296 - val_y3_pred_loss: 0.2775 - val_y4_pred_loss: 0.1546 - val_y5_pred_loss: 0.7367 - val_y6_pred_loss: 0.2236 - val_y7_pred_loss: 0.3845 - val_y_pred_categorical_accuracy: 0.7940 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "17/17 [==============================] - 12s 732ms/step - loss: 3.3930 - y_pred_loss: 0.3750 - y0_pred_loss: 0.6962 - y1_pred_loss: 0.2208 - y2_pred_loss: 0.3234 - y3_pred_loss: 0.2673 - y4_pred_loss: 0.1518 - y5_pred_loss: 0.7526 - y6_pred_loss: 0.2214 - y7_pred_loss: 0.3844 - y_pred_categorical_accuracy: 0.8636 - y0_pred_binary_accuracy: 0.7104 - y1_pred_binary_accuracy: 0.9553 - y2_pred_binary_accuracy: 0.9028 - y3_pred_binary_accuracy: 0.9312 - y4_pred_binary_accuracy: 0.9912 - y5_pred_binary_accuracy: 0.6820 - y6_pred_binary_accuracy: 0.9558 - y7_pred_binary_accuracy: 0.8713 - val_loss: 3.8338 - val_y_pred_loss: 0.8159 - val_y0_pred_loss: 0.7075 - val_y1_pred_loss: 0.2096 - val_y2_pred_loss: 0.3187 - val_y3_pred_loss: 0.2800 - val_y4_pred_loss: 0.1477 - val_y5_pred_loss: 0.7594 - val_y6_pred_loss: 0.2138 - val_y7_pred_loss: 0.3813 - val_y_pred_categorical_accuracy: 0.7855 - val_y0_pred_binary_accuracy: 0.7091 - val_y1_pred_binary_accuracy: 0.9578 - val_y2_pred_binary_accuracy: 0.9015 - val_y3_pred_binary_accuracy: 0.9254 - val_y4_pred_binary_accuracy: 0.9916 - val_y5_pred_binary_accuracy: 0.6851 - val_y6_pred_binary_accuracy: 0.9573 - val_y7_pred_binary_accuracy: 0.8724\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 13s 738ms/step - loss: 3.4046 - y_pred_loss: 0.3874 - y0_pred_loss: 0.6928 - y1_pred_loss: 0.2158 - y2_pred_loss: 0.3298 - y3_pred_loss: 0.2834 - y4_pred_loss: 0.1478 - y5_pred_loss: 0.7476 - y6_pred_loss: 0.2163 - y7_pred_loss: 0.3837 - y_pred_categorical_accuracy: 0.8596 - y0_pred_binary_accuracy: 0.7136 - y1_pred_binary_accuracy: 0.9567 - y2_pred_binary_accuracy: 0.8984 - y3_pred_binary_accuracy: 0.9236 - y4_pred_binary_accuracy: 0.9922 - y5_pred_binary_accuracy: 0.6859 - y6_pred_binary_accuracy: 0.9573 - y7_pred_binary_accuracy: 0.8723 - val_loss: 3.8569 - val_y_pred_loss: 0.8369 - val_y0_pred_loss: 0.7154 - val_y1_pred_loss: 0.2154 - val_y2_pred_loss: 0.3226 - val_y3_pred_loss: 0.2823 - val_y4_pred_loss: 0.1459 - val_y5_pred_loss: 0.7371 - val_y6_pred_loss: 0.2135 - val_y7_pred_loss: 0.3879 - val_y_pred_categorical_accuracy: 0.7898 - val_y0_pred_binary_accuracy: 0.7086 - val_y1_pred_binary_accuracy: 0.9573 - val_y2_pred_binary_accuracy: 0.9010 - val_y3_pred_binary_accuracy: 0.9249 - val_y4_pred_binary_accuracy: 0.9911 - val_y5_pred_binary_accuracy: 0.6856 - val_y6_pred_binary_accuracy: 0.9568 - val_y7_pred_binary_accuracy: 0.8719\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "          loss={'y_pred': 'categorical_crossentropy',\n",
    "                'y0_pred': 'binary_crossentropy',\n",
    "                'y1_pred': 'binary_crossentropy',\n",
    "                'y2_pred': 'binary_crossentropy',\n",
    "                'y3_pred': 'binary_crossentropy',\n",
    "                'y4_pred': 'binary_crossentropy',\n",
    "                'y5_pred': 'binary_crossentropy',\n",
    "                'y6_pred': 'binary_crossentropy',\n",
    "                'y7_pred': 'binary_crossentropy'},\n",
    "         metrics = {\n",
    "             'y_pred':['categorical_accuracy'],\n",
    "             'y0_pred':['binary_accuracy'],\n",
    "             'y1_pred':['binary_accuracy'],\n",
    "             'y2_pred':['binary_accuracy'],\n",
    "             'y3_pred':['binary_accuracy'],\n",
    "             'y4_pred':['binary_accuracy'],\n",
    "             'y5_pred':['binary_accuracy'],\n",
    "             'y6_pred':['binary_accuracy'],\n",
    "             'y7_pred':['binary_accuracy']\n",
    "         })\n",
    "hist = model.fit({'inp': X_train},\n",
    "          {'y_pred': Y_train_float,'y0_pred': yList0tf,'y1_pred': yList1tf,'y2_pred': yList2tf,'y3_pred': yList3tf,'y4_pred': yList4tf,'y5_pred': yList5tf,'y6_pred':yList6tf,'y7_pred':yList7tf}\n",
    "                 ,epochs=30, batch_size=512,validation_data=([X_test], [Y_test_float,ytestList0tf, ytestList1tf, ytestList2tf, ytestList3tf, ytestList4tf, ytestList5tf, ytestList6tf, ytestList7tf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f04d9b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7897700610042234\n",
      "pre: 0.7832509439678021\n",
      "recall: 0.7897700610042234\n",
      "F1: 0.7829773839671348\n"
     ]
    }
   ],
   "source": [
    "yOut = model.predict(X_test)\n",
    "pre = precision_score(np.argmax(y_testArr,axis=1),np.argmax(yOut[0],axis=1), average='weighted')\n",
    "acc = accuracy_score(np.argmax(y_testArr,axis=1),np.argmax(yOut[0],axis=1))\n",
    "recall = recall_score(np.argmax(y_testArr,axis=1),np.argmax(yOut[0],axis=1), average='weighted')\n",
    "F1 = f1_score(np.argmax(y_testArr,axis=1),np.argmax(yOut[0],axis=1), average='weighted')\n",
    "print('acc:',acc)\n",
    "print(\"pre:\",pre)\n",
    "print('recall:',recall)\n",
    "print('F1:',F1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
